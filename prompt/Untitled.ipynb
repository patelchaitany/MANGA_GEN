{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0101f328-cb5e-418b-b91c-0190f387448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phinex/anaconda3/envs/venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import langchain\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage,AIMessage,HumanMessage,BaseMessage,FunctionMessage\n",
    "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "import time\n",
    "from prompt import writer_prompt\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "import tqdm\n",
    "import pprint\n",
    "from textgrad.engine.groq import ChatGroq\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCE7RJhTM6Il1Fbf7zr_jsIhfSOLKTga14'\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "#model = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "class responce(BaseModel):\n",
    "    content:List[str] = Field(...,description=\"List Of Generated Story Ideas\")\n",
    "\n",
    "\n",
    "def generate_Example():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",writer_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")]\n",
    "    )\n",
    "    \n",
    "    chain =prompt | model \n",
    "    return chain\n",
    "\n",
    "def get_topic():\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=responce)\n",
    "    format_instructions = parser.get_format_instructions()\n",
    "    prompt_m = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"Please provide story idea for writing story given user requested topic. \\nGive Responce in JSON with this structure everthing follow the given structure and do give anything other than json.There should be no output before json and after json. \\n\"),\n",
    "        (\"system\",\"{format_instructions}\")\n",
    "        ,MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ])\n",
    "    prompt_m = prompt_m.partial(format_instructions=format_instructions)\n",
    "\n",
    "    chain = prompt_m |model| parser\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4271a7-6111-4011-8569-ae96a3b36aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(\"topic.jsonl\") as f:\n",
    "        \n",
    "    data_temp = f.readlines()\n",
    "    for i in data_temp:\n",
    "        data.append(json.loads(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5343c0-0de0-4f65-955d-507958e584f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad.engine.local_model_openai_api import ChatExternalClient\n",
    "from openai import OpenAI\n",
    "# client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"ollama\")\n",
    "# llm_engine = ChatExternalClient(client,\"llama3\")\n",
    "# llm_engine = tg.get_engine(\"gemini-2.0-flash-exp\")\n",
    "llm_engine = ChatGroq(\"llama-3.3-70b-versatile\")\n",
    "tg.set_backward_engine(llm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3456e8-4938-42cb-959e-e138c984a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "STARTING_SYSTEM_PROMPT = \"You are writer who write story.topic given by user ${topic}.\"\n",
    "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT, \n",
    "                            requires_grad=True, \n",
    "                            role_description=\"structured system prompt to a somewhat capable language model that will write a story given a topic.\")\n",
    "model = tg.BlackboxLLM(llm_engine, system_prompt)\n",
    "optimizer = tg.TextualGradientDescent(engine=llm_engine, parameters=[system_prompt])\n",
    "evaluation_instruction = (\n",
    "                           \"Evaluate any given answer to this question, \"\n",
    "                           \"be smart, logical, and very critical. \"\n",
    "                           \"Just provide concise feedback.\")\n",
    "\n",
    "loss_system_prompt = \"You are a smart language model that evaluates story from given topic. You do not propose story, only evaluate existing story critically and give very concise feedback on system prompt\"\n",
    "loss_system_prompt = tg.Variable(loss_system_prompt, requires_grad=False, role_description=\"system prompt to the loss function\")\n",
    "instruction = \"\"\"\n",
    "    Think About the story topic.\"\"\"\n",
    "\n",
    "format_string = \"{instruction}\\nStory Topic: {{topic}}\\nCurrent story: {{responce_story}}.\\n\"\n",
    "format_string = format_string.format(instruction=instruction)\n",
    "fields = {\"topic\":None, \"responce_story\":None}\n",
    "formatted_llm_call = tg.autograd.FormattedLLMCall(engine=llm_engine,\n",
    "                                                  format_string=format_string,\n",
    "                                                  fields=fields,\n",
    "                                                  system_prompt=loss_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e26f9e6-07fb-4e10-9e06-e3140c69c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(question:tg.Variable, answer:tg.Variable,responce:tg.Variable)->tg.Variable:\n",
    "    input = {\"topic\":question,\"responce_story\":responce}\n",
    "\n",
    "    return formatted_llm_call(inputs = input,response_role_description=f\"evaluation of the {system_prompt.get_role_description()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a69162a-e342-4cea-9e0f-da3a9bde504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[0]\n",
    "\n",
    "question_t = test[\"topic\"]\n",
    "answer_t = test[\"story\"]\n",
    "question = tg.Variable(question_t,requires_grad=False,role_description=\"topic\")\n",
    "answer = tg.Variable(answer_t,requires_grad=False,role_description=\"actual story\")\n",
    "result = model(question)\n",
    "result.set_role_description(\"generated story\")\n",
    "# result.requires_grad = False\n",
    "loss = loss_fn(question = question,answer=answer,responce=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c384fb97-e769-4d9a-a9cd-984f55fc7481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.2 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"491pt\" height=\"1063pt\"\n",
       " viewBox=\"0.00 0.00 491.02 1063.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1059.2)\">\n",
       "<polygon fill=\"lightgrey\" stroke=\"none\" points=\"-4,4 -4,-1059.2 487.02,-1059.2 487.02,4 -4,4\"/>\n",
       "<!-- 132759359117824 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>132759359117824</title>\n",
       "<polygon fill=\"lavender\" stroke=\"black\" points=\"289.02,-134.4 113.37,-134.4 113.37,0 289.02,0 289.02,-134.4\"/>\n",
       "<text text-anchor=\"start\" x=\"126.2\" y=\"-120.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n",
       "<text text-anchor=\"start\" x=\"149.45\" y=\"-120.6\" font-family=\"Arial\" font-size=\"8.00\"> Evaluation of the structured system</text>\n",
       "<text text-anchor=\"start\" x=\"128.45\" y=\"-112.6\" font-family=\"Arial\" font-size=\"8.00\">prompt to a somewhat capable language</text>\n",
       "<text text-anchor=\"start\" x=\"139.32\" y=\"-104.6\" font-family=\"Arial\" font-size=\"8.00\">model that will write a story given a</text>\n",
       "<text text-anchor=\"start\" x=\"191.82\" y=\"-96.6\" font-family=\"Arial\" font-size=\"8.00\">topic.</text>\n",
       "<text text-anchor=\"start\" x=\"130.7\" y=\"-88.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n",
       "<text text-anchor=\"start\" x=\"157.7\" y=\"-88.6\" font-family=\"Arial\" font-size=\"8.00\"> The story effectively sets up the</text>\n",
       "<text text-anchor=\"start\" x=\"138.95\" y=\"-80.6\" font-family=\"Arial\" font-size=\"8.00\">premise and establishes a sense of</text>\n",
       "<text text-anchor=\"start\" x=\"132.2\" y=\"-72.6\" font-family=\"Arial\" font-size=\"8.00\">unease. The characters are somewhat</text>\n",
       "<text text-anchor=\"start\" x=\"132.2\" y=\"-64.6\" font-family=\"Arial\" font-size=\"8.00\">archetypal but functional. The pacing is</text>\n",
       "<text text-anchor=\"start\" x=\"135.95\" y=\"-56.6\" font-family=\"Arial\" font-size=\"8.00\">good, building tension gradually. The</text>\n",
       "<text text-anchor=\"start\" x=\"146.82\" y=\"-48.6\" font-family=\"Arial\" font-size=\"8.00\">ending is a cliffhanger, which is</text>\n",
       "<text text-anchor=\"start\" x=\"131.07\" y=\"-40.6\" font-family=\"Arial\" font-size=\"8.00\">appropriate for the setup. However, the</text>\n",
       "<text text-anchor=\"start\" x=\"134.82\" y=\"-32.6\" font-family=\"Arial\" font-size=\"8.00\">descriptions could be more evocative,</text>\n",
       "<text text-anchor=\"start\" x=\"141.95\" y=\"-24.6\" font-family=\"Arial\" font-size=\"8.00\">and the entity remains too vague.</text>\n",
       "<text text-anchor=\"start\" x=\"181.7\" y=\"-16.6\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Grad Fn: </text>\n",
       "<text text-anchor=\"start\" x=\"218.45\" y=\"-16.6\" font-family=\"Arial\" font-size=\"8.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"120.57\" y=\"-8.6\" font-family=\"Arial\" font-size=\"8.00\">textgrad.autograd.llm_ops.LLMCall.backward</text>\n",
       "</g>\n",
       "<!-- 132757792354624 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>132757792354624</title>\n",
       "<polygon fill=\"lavender\" stroke=\"black\" points=\"170.4,-1055.2 0,-1055.2 0,-1000.8 170.4,-1000.8 170.4,-1055.2\"/>\n",
       "<text text-anchor=\"start\" x=\"63.45\" y=\"-1041.4\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n",
       "<text text-anchor=\"start\" x=\"86.7\" y=\"-1041.4\" font-family=\"Arial\" font-size=\"8.00\"> Topic</text>\n",
       "<text text-anchor=\"start\" x=\"7.2\" y=\"-1033.4\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n",
       "<text text-anchor=\"start\" x=\"34.2\" y=\"-1033.4\" font-family=\"Arial\" font-size=\"8.00\"> A group of friends on a camping trip</text>\n",
       "<text text-anchor=\"start\" x=\"16.95\" y=\"-1025.4\" font-family=\"Arial\" font-size=\"8.00\">discover that the woods are home to a</text>\n",
       "<text text-anchor=\"start\" x=\"15.82\" y=\"-1017.4\" font-family=\"Arial\" font-size=\"8.00\">supernatural entity that is awakened by</text>\n",
       "<text text-anchor=\"start\" x=\"59.7\" y=\"-1009.4\" font-family=\"Arial\" font-size=\"8.00\">their presence</text>\n",
       "</g>\n",
       "<!-- 132757792354624&#45;&gt;132759359117824 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>132757792354624&#45;&gt;132759359117824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M78.21,-1000.38C50.5,-889.12 -43.2,-452.93 104.2,-148.4 105.05,-146.64 105.96,-144.91 106.92,-143.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.74,-145.29 112.18,-134.98 103.84,-141.52 109.74,-145.29\"/>\n",
       "</g>\n",
       "<!-- 132757830041680 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>132757830041680</title>\n",
       "<polygon fill=\"lavender\" stroke=\"black\" points=\"289.02,-986.8 113.37,-986.8 113.37,-148.4 289.02,-148.4 289.02,-986.8\"/>\n",
       "<text text-anchor=\"start\" x=\"159.57\" y=\"-973\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n",
       "<text text-anchor=\"start\" x=\"182.82\" y=\"-973\" font-family=\"Arial\" font-size=\"8.00\"> Generated story</text>\n",
       "<text text-anchor=\"start\" x=\"122.82\" y=\"-965\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n",
       "<text text-anchor=\"start\" x=\"149.82\" y=\"-965\" font-family=\"Arial\" font-size=\"8.00\"> Okay, here&#39;s a story for you: The air</text>\n",
       "<text text-anchor=\"start\" x=\"133.32\" y=\"-957\" font-family=\"Arial\" font-size=\"8.00\">hung thick and heavy, a humid blanket</text>\n",
       "<text text-anchor=\"start\" x=\"137.45\" y=\"-949\" font-family=\"Arial\" font-size=\"8.00\">draped over the four friends as they</text>\n",
       "<text text-anchor=\"start\" x=\"138.57\" y=\"-941\" font-family=\"Arial\" font-size=\"8.00\">wrestled with their tent poles. Liam,</text>\n",
       "<text text-anchor=\"start\" x=\"136.32\" y=\"-933\" font-family=\"Arial\" font-size=\"8.00\">the self&#45;proclaimed leader, grumbled</text>\n",
       "<text text-anchor=\"start\" x=\"133.32\" y=\"-925\" font-family=\"Arial\" font-size=\"8.00\">under his breath, his brow furrowed in</text>\n",
       "<text text-anchor=\"start\" x=\"132.57\" y=\"-917\" font-family=\"Arial\" font-size=\"8.00\">concentration. Maya, ever the optimist,</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-909\" font-family=\"Arial\" font-size=\"8.00\">hummed a cheerful tune, her nimble</text>\n",
       "<text text-anchor=\"start\" x=\"135.95\" y=\"-901\" font-family=\"Arial\" font-size=\"8.00\">fingers working the pegs into the soft</text>\n",
       "<text text-anchor=\"start\" x=\"143.82\" y=\"-893\" font-family=\"Arial\" font-size=\"8.00\">earth. Chloe, the quiet observer,</text>\n",
       "<text text-anchor=\"start\" x=\"131.07\" y=\"-885\" font-family=\"Arial\" font-size=\"8.00\">sketched in her notebook, capturing the</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-877\" font-family=\"Arial\" font-size=\"8.00\">dappled sunlight filtering through the</text>\n",
       "<text text-anchor=\"start\" x=\"134.45\" y=\"-869\" font-family=\"Arial\" font-size=\"8.00\">ancient trees. And Ben, well, Ben was</text>\n",
       "<text text-anchor=\"start\" x=\"144.95\" y=\"-861\" font-family=\"Arial\" font-size=\"8.00\">mostly just trying not to trip over</text>\n",
       "<text text-anchor=\"start\" x=\"143.82\" y=\"-853\" font-family=\"Arial\" font-size=\"8.00\">anything. They were deep in the</text>\n",
       "<text text-anchor=\"start\" x=\"134.82\" y=\"-845\" font-family=\"Arial\" font-size=\"8.00\">Blackwood Forest, a place whispered</text>\n",
       "<text text-anchor=\"start\" x=\"137.45\" y=\"-837\" font-family=\"Arial\" font-size=\"8.00\">about in hushed tones in the nearby</text>\n",
       "<text text-anchor=\"start\" x=\"148.32\" y=\"-829\" font-family=\"Arial\" font-size=\"8.00\">town. Locals spoke of strange</text>\n",
       "<text text-anchor=\"start\" x=\"132.95\" y=\"-821\" font-family=\"Arial\" font-size=\"8.00\">occurrences, of unsettling silences and</text>\n",
       "<text text-anchor=\"start\" x=\"139.7\" y=\"-813\" font-family=\"Arial\" font-size=\"8.00\">a feeling of being watched. But the</text>\n",
       "<text text-anchor=\"start\" x=\"134.82\" y=\"-805\" font-family=\"Arial\" font-size=\"8.00\">friends, eager for an escape from the</text>\n",
       "<text text-anchor=\"start\" x=\"134.82\" y=\"-797\" font-family=\"Arial\" font-size=\"8.00\">city, had dismissed it as folklore. They</text>\n",
       "<text text-anchor=\"start\" x=\"139.32\" y=\"-789\" font-family=\"Arial\" font-size=\"8.00\">were here for a weekend of hiking,</text>\n",
       "<text text-anchor=\"start\" x=\"134.45\" y=\"-781\" font-family=\"Arial\" font-size=\"8.00\">campfire stories, and the simple joy of</text>\n",
       "<text text-anchor=\"start\" x=\"133.32\" y=\"-773\" font-family=\"Arial\" font-size=\"8.00\">being together. As dusk began to paint</text>\n",
       "<text text-anchor=\"start\" x=\"135.2\" y=\"-765\" font-family=\"Arial\" font-size=\"8.00\">the sky in hues of orange and purple,</text>\n",
       "<text text-anchor=\"start\" x=\"138.57\" y=\"-757\" font-family=\"Arial\" font-size=\"8.00\">they finally had their camp set up. A</text>\n",
       "<text text-anchor=\"start\" x=\"135.2\" y=\"-749\" font-family=\"Arial\" font-size=\"8.00\">crackling fire sent sparks dancing into</text>\n",
       "<text text-anchor=\"start\" x=\"143.07\" y=\"-741\" font-family=\"Arial\" font-size=\"8.00\">the twilight, casting long, dancing</text>\n",
       "<text text-anchor=\"start\" x=\"128.82\" y=\"-733\" font-family=\"Arial\" font-size=\"8.00\">shadows that seemed to writhe and twist</text>\n",
       "<text text-anchor=\"start\" x=\"135.57\" y=\"-725\" font-family=\"Arial\" font-size=\"8.00\">with a life of their own. They ate their</text>\n",
       "<text text-anchor=\"start\" x=\"137.82\" y=\"-717\" font-family=\"Arial\" font-size=\"8.00\">dinner, sharing stories and laughter,</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-709\" font-family=\"Arial\" font-size=\"8.00\">the sounds echoing in the stillness of</text>\n",
       "<text text-anchor=\"start\" x=\"134.45\" y=\"-701\" font-family=\"Arial\" font-size=\"8.00\">the woods. Later, huddled around the</text>\n",
       "<text text-anchor=\"start\" x=\"136.32\" y=\"-693\" font-family=\"Arial\" font-size=\"8.00\">fire, Liam, ever the storyteller, began</text>\n",
       "<text text-anchor=\"start\" x=\"133.32\" y=\"-685\" font-family=\"Arial\" font-size=\"8.00\">to recount the local legends. He spoke</text>\n",
       "<text text-anchor=\"start\" x=\"139.32\" y=\"-677\" font-family=\"Arial\" font-size=\"8.00\">of a creature, a being of the forest,</text>\n",
       "<text text-anchor=\"start\" x=\"135.2\" y=\"-669\" font-family=\"Arial\" font-size=\"8.00\">ancient and powerful, that slumbered</text>\n",
       "<text text-anchor=\"start\" x=\"135.57\" y=\"-661\" font-family=\"Arial\" font-size=\"8.00\">beneath the roots of the oldest trees.</text>\n",
       "<text text-anchor=\"start\" x=\"128.82\" y=\"-653\" font-family=\"Arial\" font-size=\"8.00\">He said it was awakened by disturbance,</text>\n",
       "<text text-anchor=\"start\" x=\"135.2\" y=\"-645\" font-family=\"Arial\" font-size=\"8.00\">by the intrusion of outsiders. &quot;Sounds</text>\n",
       "<text text-anchor=\"start\" x=\"140.82\" y=\"-637\" font-family=\"Arial\" font-size=\"8.00\">like a load of old wives&#39; tales,&quot; Ben</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-629\" font-family=\"Arial\" font-size=\"8.00\">scoffed, tossing another log onto the</text>\n",
       "<text text-anchor=\"start\" x=\"132.57\" y=\"-621\" font-family=\"Arial\" font-size=\"8.00\">fire. Maya, however, looked thoughtful.</text>\n",
       "<text text-anchor=\"start\" x=\"136.32\" y=\"-613\" font-family=\"Arial\" font-size=\"8.00\">&quot;But what if there&#39;s some truth to it?&quot;</text>\n",
       "<text text-anchor=\"start\" x=\"128.82\" y=\"-605\" font-family=\"Arial\" font-size=\"8.00\">she murmured, glancing nervously at the</text>\n",
       "<text text-anchor=\"start\" x=\"129.2\" y=\"-597\" font-family=\"Arial\" font-size=\"8.00\">surrounding trees. Chloe, who had been</text>\n",
       "<text text-anchor=\"start\" x=\"129.57\" y=\"-589\" font-family=\"Arial\" font-size=\"8.00\">silent, closed her notebook. &quot;The energy</text>\n",
       "<text text-anchor=\"start\" x=\"132.57\" y=\"-581\" font-family=\"Arial\" font-size=\"8.00\">here is… different,&quot; she said, her voice</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-573\" font-family=\"Arial\" font-size=\"8.00\">barely a whisper. &quot;I can feel it.&quot; They</text>\n",
       "<text text-anchor=\"start\" x=\"137.45\" y=\"-565\" font-family=\"Arial\" font-size=\"8.00\">dismissed her words, attributing it to</text>\n",
       "<text text-anchor=\"start\" x=\"129.57\" y=\"-557\" font-family=\"Arial\" font-size=\"8.00\">the spooky atmosphere. But as the night</text>\n",
       "<text text-anchor=\"start\" x=\"132.57\" y=\"-549\" font-family=\"Arial\" font-size=\"8.00\">deepened, a subtle shift occurred. The</text>\n",
       "<text text-anchor=\"start\" x=\"145.32\" y=\"-541\" font-family=\"Arial\" font-size=\"8.00\">usual sounds of the forest – the</text>\n",
       "<text text-anchor=\"start\" x=\"142.32\" y=\"-533\" font-family=\"Arial\" font-size=\"8.00\">chirping of crickets, the rustling of</text>\n",
       "<text text-anchor=\"start\" x=\"129.2\" y=\"-525\" font-family=\"Arial\" font-size=\"8.00\">leaves – seemed to fade, replaced by an</text>\n",
       "<text text-anchor=\"start\" x=\"138.57\" y=\"-517\" font-family=\"Arial\" font-size=\"8.00\">unnerving silence. The fire crackled</text>\n",
       "<text text-anchor=\"start\" x=\"144.95\" y=\"-509\" font-family=\"Arial\" font-size=\"8.00\">louder, as if trying to fill the void.</text>\n",
       "<text text-anchor=\"start\" x=\"140.45\" y=\"-501\" font-family=\"Arial\" font-size=\"8.00\">Then, they heard it. A low, guttural</text>\n",
       "<text text-anchor=\"start\" x=\"132.57\" y=\"-493\" font-family=\"Arial\" font-size=\"8.00\">hum, resonating deep within the earth.</text>\n",
       "<text text-anchor=\"start\" x=\"133.7\" y=\"-485\" font-family=\"Arial\" font-size=\"8.00\">It wasn&#39;t a sound they could place, not</text>\n",
       "<text text-anchor=\"start\" x=\"147.2\" y=\"-477\" font-family=\"Arial\" font-size=\"8.00\">an animal, not the wind. It was</text>\n",
       "<text text-anchor=\"start\" x=\"132.2\" y=\"-469\" font-family=\"Arial\" font-size=\"8.00\">something else, something ancient and</text>\n",
       "<text text-anchor=\"start\" x=\"144.2\" y=\"-461\" font-family=\"Arial\" font-size=\"8.00\">unsettling. The firelight flickered,</text>\n",
       "<text text-anchor=\"start\" x=\"125.07\" y=\"-453\" font-family=\"Arial\" font-size=\"8.00\">casting grotesque shadows that seemed to</text>\n",
       "<text text-anchor=\"start\" x=\"131.07\" y=\"-445\" font-family=\"Arial\" font-size=\"8.00\">coalesce into shapes. The trees around</text>\n",
       "<text text-anchor=\"start\" x=\"131.82\" y=\"-437\" font-family=\"Arial\" font-size=\"8.00\">them seemed to lean in, their branches</text>\n",
       "<text text-anchor=\"start\" x=\"140.45\" y=\"-429\" font-family=\"Arial\" font-size=\"8.00\">like skeletal fingers reaching out. A</text>\n",
       "<text text-anchor=\"start\" x=\"131.82\" y=\"-421\" font-family=\"Arial\" font-size=\"8.00\">cold dread washed over them, a primal</text>\n",
       "<text text-anchor=\"start\" x=\"128.45\" y=\"-413\" font-family=\"Arial\" font-size=\"8.00\">fear that went beyond the usual campfire</text>\n",
       "<text text-anchor=\"start\" x=\"130.7\" y=\"-405\" font-family=\"Arial\" font-size=\"8.00\">jitters. Liam, his bravado gone, grabbed</text>\n",
       "<text text-anchor=\"start\" x=\"137.45\" y=\"-397\" font-family=\"Arial\" font-size=\"8.00\">a flashlight, its beam cutting through</text>\n",
       "<text text-anchor=\"start\" x=\"142.32\" y=\"-389\" font-family=\"Arial\" font-size=\"8.00\">the darkness. They saw it then, a</text>\n",
       "<text text-anchor=\"start\" x=\"135.95\" y=\"-381\" font-family=\"Arial\" font-size=\"8.00\">fleeting glimpse of something moving</text>\n",
       "<text text-anchor=\"start\" x=\"132.95\" y=\"-373\" font-family=\"Arial\" font-size=\"8.00\">between the trees, a dark, amorphous</text>\n",
       "<text text-anchor=\"start\" x=\"132.95\" y=\"-365\" font-family=\"Arial\" font-size=\"8.00\">shape that seemed to absorb the light.</text>\n",
       "<text text-anchor=\"start\" x=\"136.7\" y=\"-357\" font-family=\"Arial\" font-size=\"8.00\">Panic set in. They scrambled to their</text>\n",
       "<text text-anchor=\"start\" x=\"132.95\" y=\"-349\" font-family=\"Arial\" font-size=\"8.00\">feet, their laughter replaced by ragged</text>\n",
       "<text text-anchor=\"start\" x=\"125.45\" y=\"-341\" font-family=\"Arial\" font-size=\"8.00\">breaths. The hum grew louder, the ground</text>\n",
       "<text text-anchor=\"start\" x=\"134.07\" y=\"-333\" font-family=\"Arial\" font-size=\"8.00\">beneath them vibrating with its power.</text>\n",
       "<text text-anchor=\"start\" x=\"139.32\" y=\"-325\" font-family=\"Arial\" font-size=\"8.00\">They knew, with a chilling certainty,</text>\n",
       "<text text-anchor=\"start\" x=\"130.32\" y=\"-317\" font-family=\"Arial\" font-size=\"8.00\">that they had awakened something they</text>\n",
       "<text text-anchor=\"start\" x=\"127.32\" y=\"-309\" font-family=\"Arial\" font-size=\"8.00\">couldn&#39;t comprehend, something that was</text>\n",
       "<text text-anchor=\"start\" x=\"128.82\" y=\"-301\" font-family=\"Arial\" font-size=\"8.00\">now aware of their presence. They were</text>\n",
       "<text text-anchor=\"start\" x=\"135.95\" y=\"-293\" font-family=\"Arial\" font-size=\"8.00\">no longer just campers in the woods.</text>\n",
       "<text text-anchor=\"start\" x=\"129.95\" y=\"-285\" font-family=\"Arial\" font-size=\"8.00\">They were intruders, and the forest was</text>\n",
       "<text text-anchor=\"start\" x=\"130.7\" y=\"-277\" font-family=\"Arial\" font-size=\"8.00\">about to make them pay. The night was</text>\n",
       "<text text-anchor=\"start\" x=\"131.45\" y=\"-269\" font-family=\"Arial\" font-size=\"8.00\">young, and the entity was awake. Their</text>\n",
       "<text text-anchor=\"start\" x=\"128.07\" y=\"-261\" font-family=\"Arial\" font-size=\"8.00\">weekend of escape had just turned into a</text>\n",
       "<text text-anchor=\"start\" x=\"137.07\" y=\"-253\" font-family=\"Arial\" font-size=\"8.00\">fight for survival. The woods, once a</text>\n",
       "<text text-anchor=\"start\" x=\"133.32\" y=\"-245\" font-family=\"Arial\" font-size=\"8.00\">place of peace, had become a hunting</text>\n",
       "<text text-anchor=\"start\" x=\"135.57\" y=\"-237\" font-family=\"Arial\" font-size=\"8.00\">ground, and they were the prey. The</text>\n",
       "<text text-anchor=\"start\" x=\"134.45\" y=\"-229\" font-family=\"Arial\" font-size=\"8.00\">story ends here, leaving the reader to</text>\n",
       "<text text-anchor=\"start\" x=\"142.32\" y=\"-221\" font-family=\"Arial\" font-size=\"8.00\">imagine the terror that awaits the</text>\n",
       "<text text-anchor=\"start\" x=\"140.82\" y=\"-213\" font-family=\"Arial\" font-size=\"8.00\">friends. It&#39;s a classic setup, playing</text>\n",
       "<text text-anchor=\"start\" x=\"126.2\" y=\"-205\" font-family=\"Arial\" font-size=\"8.00\">on the fear of the unknown and the power</text>\n",
       "<text text-anchor=\"start\" x=\"128.82\" y=\"-197\" font-family=\"Arial\" font-size=\"8.00\">of nature. What do you think? Would you</text>\n",
       "<text text-anchor=\"start\" x=\"134.82\" y=\"-189\" font-family=\"Arial\" font-size=\"8.00\">like me to continue the story, perhaps</text>\n",
       "<text text-anchor=\"start\" x=\"134.07\" y=\"-181\" font-family=\"Arial\" font-size=\"8.00\">exploring the entity further or focusing</text>\n",
       "<text text-anchor=\"start\" x=\"138.95\" y=\"-173\" font-family=\"Arial\" font-size=\"8.00\">on the friends&#39; attempts to escape?</text>\n",
       "<text text-anchor=\"start\" x=\"181.7\" y=\"-165\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Grad Fn: </text>\n",
       "<text text-anchor=\"start\" x=\"218.45\" y=\"-165\" font-family=\"Arial\" font-size=\"8.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"120.57\" y=\"-157\" font-family=\"Arial\" font-size=\"8.00\">textgrad.autograd.llm_ops.LLMCall.backward</text>\n",
       "</g>\n",
       "<!-- 132757792354624&#45;&gt;132757830041680 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>132757792354624&#45;&gt;132757830041680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.9,-1000.3C96.41,-995.82 97.9,-991.19 99.2,-986.8 102.78,-974.67 106.33,-962.32 109.85,-949.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.2,-950.85 112.52,-940.28 106.46,-948.97 113.2,-950.85\"/>\n",
       "</g>\n",
       "<!-- 132757830041680&#45;&gt;132759359117824 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>132757830041680&#45;&gt;132759359117824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201.2,-148C201.2,-147.29 201.2,-146.57 201.2,-145.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.7,-146.24 201.2,-136.24 197.7,-146.24 204.7,-146.24\"/>\n",
       "</g>\n",
       "<!-- 132757792355056 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>132757792355056</title>\n",
       "<polygon fill=\"lavender\" stroke=\"black\" points=\"483.02,-598.8 307.38,-598.8 307.38,-536.4 483.02,-536.4 483.02,-598.8\"/>\n",
       "<text text-anchor=\"start\" x=\"321.32\" y=\"-585\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n",
       "<text text-anchor=\"start\" x=\"344.57\" y=\"-585\" font-family=\"Arial\" font-size=\"8.00\"> System prompt to the loss function</text>\n",
       "<text text-anchor=\"start\" x=\"314.57\" y=\"-577\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n",
       "<text text-anchor=\"start\" x=\"341.57\" y=\"-577\" font-family=\"Arial\" font-size=\"8.00\"> You are a smart language model that</text>\n",
       "<text text-anchor=\"start\" x=\"324.7\" y=\"-569\" font-family=\"Arial\" font-size=\"8.00\">evaluates story from given topic. You do</text>\n",
       "<text text-anchor=\"start\" x=\"338.57\" y=\"-561\" font-family=\"Arial\" font-size=\"8.00\">not propose story, only evaluate</text>\n",
       "<text text-anchor=\"start\" x=\"332.95\" y=\"-553\" font-family=\"Arial\" font-size=\"8.00\">existing story critically and give very</text>\n",
       "<text text-anchor=\"start\" x=\"331.82\" y=\"-545\" font-family=\"Arial\" font-size=\"8.00\">concise feedback on system prompt</text>\n",
       "</g>\n",
       "<!-- 132757792355056&#45;&gt;132759359117824 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>132757792355056&#45;&gt;132759359117824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M394.65,-535.99C392.04,-463.26 377.49,-276.6 298.2,-148.4 297.19,-146.77 296.14,-145.16 295.05,-143.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.07,-141.77 289.28,-135.86 292.47,-145.96 298.07,-141.77\"/>\n",
       "</g>\n",
       "<!-- 132757792354240 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>132757792354240</title>\n",
       "<polygon fill=\"lavender\" stroke=\"black\" points=\"375.65,-1051.2 188.75,-1051.2 188.75,-1004.8 375.65,-1004.8 375.65,-1051.2\"/>\n",
       "<text text-anchor=\"start\" x=\"195.95\" y=\"-1037.4\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Role: </text>\n",
       "<text text-anchor=\"start\" x=\"219.2\" y=\"-1037.4\" font-family=\"Arial\" font-size=\"8.00\"> Structured system prompt to a somewhat</text>\n",
       "<text text-anchor=\"start\" x=\"211.32\" y=\"-1029.4\" font-family=\"Arial\" font-size=\"8.00\">capable language model that will write a</text>\n",
       "<text text-anchor=\"start\" x=\"249.2\" y=\"-1021.4\" font-family=\"Arial\" font-size=\"8.00\">story given a topic.</text>\n",
       "<text text-anchor=\"start\" x=\"213.2\" y=\"-1013.4\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"8.00\" fill=\"darkblue\">Value: </text>\n",
       "<text text-anchor=\"start\" x=\"240.2\" y=\"-1013.4\" font-family=\"Arial\" font-size=\"8.00\"> You are writer who write story.</text>\n",
       "</g>\n",
       "<!-- 132757792354240&#45;&gt;132757830041680 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>132757792354240&#45;&gt;132757830041680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.24,-1004.58C277.88,-1002.58 277.51,-1000.46 277.12,-998.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.58,-997.7 275.39,-988.46 273.68,-998.92 280.58,-997.7\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x78be0f714530>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f887221-11f5-49c2-8b29-9b1e976f850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae9167c-5995-47ca-b0d2-1343b801ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=You are writer who write story.topic given by user ${topic}., role=structured system prompt to a somewhat capable language model that will write a story given a topic., grads=set())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93be164-ca85-4a43-98fe-410fb40053ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7315a75b-656b-4b02-877e-95c6b1e9d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef86a124-c492-4593-aca8-b2f03dcc930d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:51<00:00, 17.13s/it]\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7e76bfb2c6b0 state=finished raised RateLimitError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/engine/openai.py:71\u001b[0m, in \u001b[0;36mChatOpenAI.generate\u001b[0;34m(self, content, system_prompt, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_from_single_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/engine/openai.py:90\u001b[0m, in \u001b[0;36mChatOpenAI._generate_from_single_prompt\u001b[0;34m(self, prompt, system_prompt, temperature, max_tokens, top_p)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache_or_none\n\u001b[0;32m---> 90\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msys_prompt_arg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/groq/resources/chat/completions.py:316\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mCreates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/groq/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m )\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/groq/_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/groq/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j4219vd0epdtyx4tmyvggx9c` service tier `on_demand` on : Limit 100000, Used 97157, Requested 2918. Please try again in 1m4.048999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss_f\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     13\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m tg\u001b[38;5;241m.\u001b[39msum(loss_f)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m((system_prompt\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/variable.py:179\u001b[0m, in \u001b[0;36mVariable.backward\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    177\u001b[0m v\u001b[38;5;241m.\u001b[39mgradients \u001b[38;5;241m=\u001b[39m _check_and_reduce_gradients(v, backward_engine)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mget_grad_fn() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/autograd/function.py:57\u001b[0m, in \u001b[0;36mBackwardContext.__call__\u001b[0;34m(self, backward_engine)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, backward_engine: EngineLM):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/autograd/llm_ops.py:98\u001b[0m, in \u001b[0;36mLLMCall.backward\u001b[0;34m(self, response, prompt, system_prompt, backward_engine)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_through_llm_base(children_variables, response, prompt, system_prompt, backward_engine)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_through_llm_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchildren_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/autograd/llm_ops.py:149\u001b[0m, in \u001b[0;36mLLMCall._backward_through_llm_chain\u001b[0;34m(variables, response, prompt, system_prompt, backward_engine)\u001b[0m\n\u001b[1;32m    146\u001b[0m backward_prompt \u001b[38;5;241m=\u001b[39m LLMCall\u001b[38;5;241m.\u001b[39m_construct_llm_chain_backward_prompt(backward_info)\n\u001b[1;32m    148\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_backward_through_llm prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_backward_through_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m: backward_prompt})\n\u001b[0;32m--> 149\u001b[0m gradient_value \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBACKWARD_SYSTEM_PROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_backward_through_llm gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_backward_through_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m: gradient_value})\n\u001b[1;32m    152\u001b[0m var_gradients \u001b[38;5;241m=\u001b[39m Variable(value\u001b[38;5;241m=\u001b[39mgradient_value, role_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;241m.\u001b[39mget_role_description()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/textgrad/engine/openai.py:109\u001b[0m, in \u001b[0;36mChatOpenAI.__call__\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.12/site-packages/tenacity/__init__.py:419\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7e76bfb2c6b0 state=finished raised RateLimitError>]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open(\"prompt.jsonl\",\"w\") as f:\n",
    "    for epoch in range(3):\n",
    "        loss_f = []\n",
    "        optimizer.zero_grad()\n",
    "        for i in tqdm.tqdm(new_data):\n",
    "            question_t = i[\"topic\"]\n",
    "            answer_t = i[\"story\"]\n",
    "            question = tg.Variable(question_t,requires_grad=False,role_description=\"topic\")\n",
    "            answer = tg.Variable(answer_t,requires_grad=False,role_description=\"actual story\")\n",
    "            result = model(question)\n",
    "            loss = loss_fn(question = question,answer=answer,responce=result)\n",
    "            loss_f.append(loss)\n",
    "        total_loss = tg.sum(loss_f)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        print((system_prompt.value))\n",
    "        f.write(json.dumps({\"epoch\":epoch,\"system_prompt\":system_prompt.value}))\n",
    "        f.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
